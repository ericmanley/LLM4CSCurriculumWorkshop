{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C192SOmJS6lw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting Started with Large Language Models for the CS Curriculum\n",
    "\n",
    "Eric Manley\n",
    "\n",
    "Drake University\n",
    "\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/LLM4CSCurriculumWorkshop/blob/main/LLM_Workshop.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Purpose of the workshop\n",
    "\n",
    "* Demonstrate how to use the **transformers** Python library\n",
    "* Discuss where it can be used in college CS curricula\n",
    "* Share resources for further learning and course development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers in a nutshell\n",
    "\n",
    "A **transformer** is a neural network architecture based on the concept of **attention**\n",
    "* they're what make LLMs work - behind ChatGPT et al.\n",
    "* You feed a lot of text data into the neural network, and it learns which words relate to other words\n",
    "\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <td><img src=\"images/simple_self_attention.png\" width=400px></td>\n",
    "                <td><img src=\"images/attention_vis1.png\" width=300px></td>\n",
    "            </tr>\n",
    "        </table>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "\n",
    "*image source:* Speech and Language Processing Fig. 10.2, https://web.stanford.edu/~jurafsky/slp3/10.pdf\n",
    "\n",
    "*image source:* from the original paper on transformers - **attention is all you need** https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why transformers?\n",
    "\n",
    "Unlike previous neural network architectures, they can be trained *in parallel*\n",
    "\n",
    "LLMs use big models (take lots of words as input, encodings for lots of word senses, lots of layers for extracting high level features of text, trained on massive amounts of text)\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "        <img src=\"images/transformer_encoder_decoder.png\" width=300px>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "*image source:* Hugging Face NLP Course - **How do transformers work?** https://huggingface.co/learn/nlp-course/chapter1/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing the Hugging Face `transformers` library\n",
    "\n",
    "You can install it with pip - this code should work running it locally or in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### What is Hugging Face?\n",
    "\n",
    "Hugging Face is a private company\n",
    "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
    "* Based in New York City\n",
    "\n",
    "Provide popular free, open-source libraries for natural language processing (and other) tasks\n",
    "\n",
    "Host *hundreds of thousands of models* that you can use in your own programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A first tranformers program: the sentiment analysis pipeline\n",
    "\n",
    "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
    "\n",
    "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
    "\n",
    "A **pipeline** is a series of steps for performing **inference**\n",
    "* tokenize and preprocess the input text (more on this later)\n",
    "* ask the model for a prediction\n",
    "* post-process model's result and turn it into something you can use\n",
    "\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "        <img src=\"images/full_nlp_pipeline.svg\" width=600px>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We *are* specifying the kind of task: `sentiment-analysis`\n",
    "\n",
    "We *are not* asking for a specific model, so it picks one of many it has by default\n",
    "\n",
    "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9984305500984192}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "results = classifier(\"I love how easy it is to build sentiment-aware applications with the transformers library!\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test it out:** Try changing the input to get different labels/scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Specifying a model\n",
    "\n",
    "Now try asking for a specific model. \n",
    "\n",
    "Replace one line of code in your earlier example.\n",
    "\n",
    "You can find out more about this model by checking out its model card: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
    "\n",
    "What are some things you notice about this model that are different than the first one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Explore additional models\n",
    "\n",
    "Go to the Hugging Face models page: https://huggingface.co/models\n",
    "* click `Text Classification`\n",
    "* find another model that looks interesting to you and try it out\n",
    "* you might be able to find models for spam detection, fake news detection, topic classification, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about sequence-to-sequence models?\n",
    "\n",
    "The transformers library has models for generating output sequences - long text as input and output\n",
    "* summarization\n",
    "* translation\n",
    "* question answering\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada6210f0ebd4f15b1c26e7cc257383a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecb941f669f437b83c1e69444b5ceb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfa6eb1401744b1863a4947f00e8190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941adbdcc9d24ad79a893ddc69319f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f064cbc60a1f4d9bad0225629ce3a46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article copied from https://www.npr.org/2024/04/02/1242197022/biden-xi-jinping-call-china\n",
    "example_news_article = \"\"\"\n",
    "BEIJING and WASHINGTON, D.C. — President Biden and Chinese leader Xi Jinping held what a senior Biden administration official dubbed a \"check-in\" call on Tuesday, marking the first conversation between the leaders since their face-to-face meeting in California in November.\n",
    "The latest thorn in Taiwan-China tensions: pineapples\n",
    "World\n",
    "The latest thorn in Taiwan-China tensions: pineapples\n",
    "\n",
    "The call touched on everything from Taiwan to the situation on the Korean Peninsula, artificial intelligence and Russia's war in Ukraine.\n",
    "\n",
    "According to the Chinese readout, Xi told Biden strategic awareness \"must always be the first 'button' to be fastened\" in bilateral ties. The Chinese leader also elaborated his position on issues concerning Hong Kong, human rights and the South China Sea, the readout says.\n",
    "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
    "World\n",
    "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
    "\n",
    "The Chinese leader warned again that the \"Taiwan issue\" is an \"insurmountable red line\" in bilateral ties. Xi also urged Biden to \"translate\" his commitment of not supporting \"Taiwan independence\" into concrete actions, according to the readout.\n",
    "\n",
    "Biden, in the call, emphasized the importance of maintaining peace and stability across the Taiwan Strait and the rule of law and freedom of navigation in the South China Sea, according to a White House readout.\n",
    "\n",
    "The two leaders also discussed the global geopolitical situation. Biden, according to the White House, raised concerns over China's support for Russia's defense industrial base and its impact on European and transatlantic security. He also emphasized Washington's \"enduring commitment\" to the complete denuclearization of the Korean Peninsula.\n",
    "\n",
    "Tuesday's call was the first time Biden and Xi have talked since they met in northern California in November. There, they agreed on a range of steps to try to prevent increasingly fraught U.S.-China ties from slipping into conflict, including more frequent contact at the leader level, between militaries and beyond.\n",
    "\n",
    "Ahead of the call, a senior administration official told reporters the conversation would not represent a change in U.S. policy toward China, and competition remains a key feature.\n",
    "\n",
    "\"Intense competition requires intense diplomacy to manage tensions, address misperceptions and prevent unintended conflict. And this call is one way to do that,\" said the official, who spoke on condition of anonymity as he was not permitted to speak on the record.\n",
    "\n",
    "Biden raised perennial U.S. concerns about China's \"unfair trade policies and non-market economic practices,\" according to the White House readout — an issue that will be front and center when Treasury Secretary Janet Yellen visits China later this week.\n",
    "\n",
    "The president also reiterated to his Chinese counterpart that Washington will continue to \"take necessary actions to prevent advanced U.S. technologies from being used to undermine our national security, without unduly limiting trade and investment,\" the White House readout said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' President Biden and Chinese leader Xi Jinping held what a senior Biden administration official dubbed a \"check-in\" call on Tuesday . The call touched on everything from Taiwan to the situation on the Korean Peninsula, artificial intelligence and Russia\\'s war in Ukraine . Tuesday\\'s call was the first time Biden and Xi have talked since they met in northern California in November .'}]\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(example_news_article)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about chat bots?\n",
    "\n",
    "Chat bots need models that have been trained on conversational text. \n",
    "\n",
    "To get the next response in a conversational thread, you need to pass in the entire conversation up to that point.\n",
    "\n",
    "Models often use special tokens like `<s>` and `</s>` to indicate where a sequence begins and ends, but it is different for different models: https://huggingface.co/docs/transformers/en/model_doc/blenderbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93c00d7081940d3aec60de482737295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59db389da5c4de8a42fe6ee1d7b4400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb55d465312443e9dea4c55d73c11a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0939325e334c4cbf4802255a66c6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580147ab45bd4c669f1a041db16a7855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/127k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a93841f9c841f5b5f504225e7e2c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/62.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44584536f0f14035a0d9c071d1f49e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7fc506e0a9433fa7d7ed54c73f8d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_gen = pipeline(\"text2text-generation\", model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Computer science is a branch of mathematics that deals with computing.'}]\n"
     ]
    }
   ],
   "source": [
    "conversation = \"<s>What is computer science?</s>\"\n",
    "result = text_gen(conversation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Yes, it is the study of algorithms and the theory of computation.'}]\n"
     ]
    }
   ],
   "source": [
    "conversation += \"<s>\"+result[0][\"generated_text\"]+\"</s>\"\n",
    "conversation += \"<s>Is it only related to math?</s>\"\n",
    "result = text_gen(conversation)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>What is computer science?</s><s> Computer science is a branch of mathematics that deals with computing.</s><s>Is it only related to math?</s><s> Yes, it is the study of algorithms and the theory of computation.</s>\n"
     ]
    }
   ],
   "source": [
    "conversation += \"<s>\"+result[0][\"generated_text\"]+\"</s>\"\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about data?\n",
    "\n",
    "Hugging Face also hosts lots of useful data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /Users/000794593/Library/Python/3.10/lib/python/site-packages (2.14.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from fsspec[http]>=2021.11.1->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f94cdb273de40cda26e4a20ed82709d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bb422726ec432c8e1afc50c06c5aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa9d8d0ceaa4f08a9cac983680e1d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/347k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e74e9e11f649beb55ef2c5d035d31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82d28d47962446b9bb821b984be39ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/350k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eee0a305c44a2a8fd3cf8ba64e2813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e480d95368374a23be7872aeacd1481c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d47a2cf1f2047819ce0816672455715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48717c480d9e40c6959b32fde176fe71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'id'],\n",
       "        num_rows: 5427\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'id'],\n",
       "        num_rows: 43410\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'labels', 'id'],\n",
       "        num_rows: 5426\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first text in the dataset: I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\n",
      "The first text in the dataset: [25]\n",
      "What does that label mean? sadness\n"
     ]
    }
   ],
   "source": [
    "print(\"The first text in the dataset:\",dataset[\"test\"][\"text\"][0])\n",
    "print(\"The first text in the dataset:\",dataset[\"test\"][\"labels\"][0])\n",
    "print(\"What does that label mean?\",dataset[\"test\"].features[\"labels\"].feature.int2str(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about large models?\n",
    "\n",
    "Large models take a lot of resources to work with\n",
    "\n",
    "Many large models have smaller cousins that can be used for test purposes\n",
    "\n",
    "For example, the T5 model comes in different sizes, ranging from 60 million parameters to 11 billion: https://huggingface.co/google-t5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discussion\n",
    "\n",
    "Where do you see language models fitting into the curriculum?\n",
    "\n",
    "From what we've covered today, is there anything that is accessible to CS 1 or CS 2? Does it make sense to introduce it there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "Free NLP Textbook: Speech and Language Processing by Dan Jurafsky and James H. Martin \n",
    "* https://web.stanford.edu/~jurafsky/slp3/\n",
    "* great for theoretical and intuitive understanding of concepts\n",
    "\n",
    "Hugging Face NLP Course: https://huggingface.co/learn/nlp-course/\n",
    "* great for engineering/implementation\n",
    "\n",
    "Course Materials: https://github.com/ericmanley/F23-CS195NLP\n",
    "* Natural Language Processing course for undergrads that includes lots of implementation\n",
    "* Includes Jupyter Notebooks like this one\n",
    "\n",
    "Fine-Tuning Models for new data\n",
    "* Hugging Face fine-tuning chapter: https://huggingface.co/learn/nlp-course/chapter3/1\n",
    "* From my NLP course: https://github.com/ericmanley/F23-CS195NLP/blob/main/F7_1_TransferLearning.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOf2oi4GbgdvkO0orSdgZtQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
